{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4418193e-28a3-49ca-85ef-c94e7d75b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq()\n",
    "# Specify the model to be used (we recommend Llama 3.3 70B)\n",
    "MODEL = 'llama-3.1-8b-instant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59207d3d-ef6a-4366-ade5-0b1b0e85f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(expression):\n",
    "    \"\"\"Evaluate a mathematical expression\"\"\"\n",
    "    try:\n",
    "        # Attempt to evaluate the math expression\n",
    "        result = eval(expression)\n",
    "        return json.dumps({\"result\": result})\n",
    "    except:\n",
    "        # Return an error message if the math expression is invalid\n",
    "        return json.dumps({\"error\": \"Invalid expression\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6615dc7b-eb89-49cf-aa07-5e316c2f6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports calculate function from step 1\n",
    "def run_conversation(user_prompt):\n",
    "    # Initialize the conversation with system and user messages\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "    # Define the available tools (i.e. functions) for our model to use\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"calculate\",\n",
    "                \"description\": \"Evaluate a mathematical expression\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The mathematical expression to evaluate\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    # Make the initial API call to Groq\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL, # LLM to use\n",
    "        messages=messages, # Conversation history\n",
    "        stream=False,\n",
    "        tools=tools, # Available tools (i.e. functions) for our LLM to use\n",
    "        tool_choice=\"auto\", # Let our LLM decide when to use tools\n",
    "        max_completion_tokens=4096 # Maximum number of tokens to allow in our response\n",
    "    )\n",
    "    # Extract the response and any tool call responses\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        # Define the available tools that can be called by the LLM\n",
    "        available_functions = {\n",
    "            \"calculate\": calculate,\n",
    "        }\n",
    "        # Add the LLM's response to the conversation\n",
    "        messages.append(response_message)\n",
    "\n",
    "        # Process each tool call\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            # Call the tool and get the response\n",
    "            function_response = function_to_call(\n",
    "                expression=function_args.get(\"expression\")\n",
    "            )\n",
    "            # Add the tool response to the conversation\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id, \n",
    "                    \"role\": \"tool\", # Indicates this message is from tool use\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "        # Make a second API call with the updated conversation\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "        # Return the final response\n",
    "        return second_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6326a6ce-ca46-40c8-994d-7065f4b36928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the expression 25 * 4 + 10 is 110.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_prompt = \"What is 25 * 4 + 10?\"\n",
    "print(run_conversation(user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090deaf-7cf9-4e12-ad36-5c78471a2e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56165e2-d134-476f-af8b-9b03d89b0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports calculate function from step 1\n",
    "user_prompt = \"What is 25 * 4 + 10?\"\n",
    "# Initialize the conversation with system and user messages\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3d343e-6ce0-4d9e-b399-cae8c9c29d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the available tools (i.e. functions) for our model to use\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Evaluate a mathematical expression\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The mathematical expression to evaluate\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f81ac46-8e93-484e-8d3a-924ee68ced9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the initial API call to Groq\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL, # LLM to use\n",
    "    messages=messages, # Conversation history\n",
    "    stream=False,\n",
    "    tools=tools, # Available tools (i.e. functions) for our LLM to use\n",
    "    tool_choice=\"auto\", # Let our LLM decide when to use tools\n",
    "    max_completion_tokens=4096 # Maximum number of tokens to allow in our response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68980719-f5e6-4743-a7bf-590dd847521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='02x0k9a9g', function=Function(arguments='{\"expression\":\"25 * 4 + 10\"}', name='calculate'), type='function')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f2dc2d4-bcc4-4be2-8cf2-b62610a7ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the response and any tool call responses\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "if tool_calls:\n",
    "    # Define the available tools that can be called by the LLM\n",
    "    available_functions = {\n",
    "        \"calculate\": calculate,\n",
    "    }\n",
    "    # Add the LLM's response to the conversation\n",
    "    messages.append(response_message)\n",
    "\n",
    "    # Process each tool call\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        # Call the tool and get the response\n",
    "        function_response = function_to_call(\n",
    "            expression=function_args.get(\"expression\")\n",
    "        )\n",
    "        # Add the tool response to the conversation\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id, \n",
    "                \"role\": \"tool\", # Indicates this message is from tool use\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "    # Make a second API call with the updated conversation\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7ba6eb4-7c31-415e-9cbd-d5795179cf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result of the operation 25 * 4 + 10 is 110.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the final response\n",
    "second_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e48ad366-5f0a-4004-a2df-5075c9ae1f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result of the operation 25 * 4 + 10 is 110.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95429be7-4d8c-4121-a8e7-ea7b6d16716c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af6194ea-8554-4822-86ab-fe12d3f710b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weather tools\n",
    "def get_temperature(location: str):\n",
    "    # This is a mock tool/function. In a real scenario, you would call a weather API.\n",
    "    temperatures = {\"New York\": \"22°C\", \"London\": \"18°C\", \"Tokyo\": \"26°C\", \"Sydney\": \"20°C\"}\n",
    "    return temperatures.get(location, \"Temperature data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df0da7e1-33a5-4a0a-9563-62184dcd8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_condition(location: str):\n",
    "    # This is a mock tool/function. In a real scenario, you would call a weather API.\n",
    "    conditions = {\"New York\": \"Sunny\", \"London\": \"Rainy\", \"Tokyo\": \"Cloudy\", \"Sydney\": \"Clear\"}\n",
    "    return conditions.get(location, \"Weather condition data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ba5f68e-98a1-418e-ae09-19862baaed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system messages and tools\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful weather assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather and temperature like in New York and London? Respond with one sentence for each city. Use tools to get the information.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44dc655b-f70a-4672-9d09-c3ff0963d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_temperature\",\n",
    "            \"description\": \"Get the temperature for a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the city\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather_condition\",\n",
    "            \"description\": \"Get the weather condition for a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the city\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "701303c8-4f9b-40e4-84f0-75362526de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the initial request\n",
    "response = client.chat.completions.create(\n",
    "    model=model, messages=messages, tools=tools, tool_choice=\"auto\", max_completion_tokens=4096, temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "433d3a4b-833a-44ed-a588-b53724b32afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa6e2ea8-fa8d-4486-8038-c0fffdf391cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='jjdv6j976', function=Function(arguments='{\"location\":\"New York\"}', name='get_temperature'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='ptvxjswry', function=Function(arguments='{\"location\":\"London\"}', name='get_temperature'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='9z3hzey2p', function=Function(arguments='{\"location\":\"New York\"}', name='get_weather_condition'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='c2cy59955', function=Function(arguments='{\"location\":\"London\"}', name='get_weather_condition'), type='function')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb0d3c58-a05d-4d47-b9c2-d808e6cd4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tool calls\n",
    "messages.append(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3bc0b27-c531-4c22-8c47-60685c2568d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful weather assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': \"What's the weather and temperature like in New York and London? Respond with one sentence for each city. Use tools to get the information.\"},\n",
       " ChatCompletionMessage(content=None, role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=[ChatCompletionMessageToolCall(id='jjdv6j976', function=Function(arguments='{\"location\":\"New York\"}', name='get_temperature'), type='function'), ChatCompletionMessageToolCall(id='ptvxjswry', function=Function(arguments='{\"location\":\"London\"}', name='get_temperature'), type='function'), ChatCompletionMessageToolCall(id='9z3hzey2p', function=Function(arguments='{\"location\":\"New York\"}', name='get_weather_condition'), type='function'), ChatCompletionMessageToolCall(id='c2cy59955', function=Function(arguments='{\"location\":\"London\"}', name='get_weather_condition'), type='function')])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66fbf8cc-b01d-4555-8dfd-92e06c6efc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"get_temperature\": get_temperature,\n",
    "    \"get_weather_condition\": get_weather_condition,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a0f726c-bce8-40f5-aacd-b71f6d1d26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in tool_calls:\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": str(function_response),\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73906191-2f1c-4d3f-ad9a-c40fc00749db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the final request with tool call results\n",
    "final_response = client.chat.completions.create(\n",
    "    model=model, messages=messages, tools=tools, tool_choice=\"auto\", max_completion_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15078115-453d-435d-a7f2-499095558355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that the actual temperatures and weather conditions may change frequently. The above responses are just examples. If you want up-to-date information, you can use APIs or other tools that provide real-time weather data. \n",
      "\n",
      "For this example, I assumed the temperature in New York is 22°C and in London is 18°C, and the weather condition in New York is Sunny and in London is Rainy, which might not reflect the actual current weather in these cities.\n"
     ]
    }
   ],
   "source": [
    "print(final_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d4ed0-9361-4c39-ae8d-f7b4b2782d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b217f99f-d9ed-4334-be26-1509b7be8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "093abf33-1fb7-4856-a682-e27ea7f1be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool schema\n",
    "tool_schema = {\n",
    "    \"name\": \"get_weather_info\",\n",
    "    \"description\": \"Get the weather information for any location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The location for which we want to get the weather information (e.g., New York)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0946adc4-aff8-499d-ae69-85f87b2687ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic model for the tool call\n",
    "class ToolCall(BaseModel):\n",
    "    input_text: str = Field(description=\"The user's input text\")\n",
    "    tool_name: str = Field(description=\"The name of the tool to call\")\n",
    "    tool_parameters: str = Field(description=\"JSON string of tool parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc84c1b3-5089-4a86-a123-58becb7f76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseModel(BaseModel):\n",
    "    tool_calls: list[ToolCall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa1993a9-f60b-43cb-99fa-06ba31724bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch Groq() with instructor\n",
    "client = instructor.from_groq(Groq(), mode=instructor.Mode.JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47d19125-32cd-4e49-8f9d-c0e1cad31282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(user_prompt):\n",
    "    # Prepare the messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You are an assistant that can use tools. You have access to the following tool: {tool_schema}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Make the Groq API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_model=ResponseModel,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_completion_tokens=1000,\n",
    "    )\n",
    "\n",
    "    return response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da7a5e4f-a6cc-45db-98e2-6e3586ce35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "user_prompt = \"What's the weather like in San Francisco?\"\n",
    "tool_calls = run_conversation(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc9b3580-d6e8-4402-b636-9f3e1bd7a9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCall(input_text=\"What's the weather like in San Francisco?\", tool_name='get_weather_info', tool_parameters='{\"location\": \"San Francisco\"}')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f050e66f-16dd-44e9-a755-2dd36e3a5ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What's the weather like in San Francisco?\n",
      "Tool: get_weather_info\n",
      "Parameters: {\"location\": \"San Francisco\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for call in tool_calls:\n",
    "    print(f\"Input: {call.input_text}\")\n",
    "    print(f\"Tool: {call.tool_name}\")\n",
    "    print(f\"Parameters: {call.tool_parameters}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9629ac0-486c-4b55-b722-4be451b93358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83d1dc-322d-40bf-a337-4b732e49d0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac4b2ebf-b393-46dc-bc7d-6ceab00e37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool schema\n",
    "tool_schema = {\n",
    "    \"name\": \"get_weather_info\",\n",
    "    \"description\": \"Get the weather information for any location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The location for which we want to get the weather information (e.g., New York)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d2ec448-783f-495f-98a0-dc45bf76ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic model for the tool call\n",
    "class ToolCall(BaseModel):\n",
    "    input_text: str = Field(description=\"The user's input text\")\n",
    "    tool_name: str = Field(description=\"The name of the tool to call\")\n",
    "    tool_parameters: str = Field(description=\"JSON string of tool parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46ec75e7-2ef7-4c1b-9960-172695909052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseModel(BaseModel):\n",
    "    tool_calls: list[ToolCall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "784d3727-91e3-4530-9c20-fb8dc23a1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch Groq() with instructor\n",
    "client = instructor.from_groq(Groq(), mode=instructor.Mode.JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c139b1e-a09d-4fab-a36f-6e7a0c385094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(user_prompt):\n",
    "    # Prepare the messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You are an assistant that can use tools. You have access to the following tool: {tool_schema}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Make the Groq API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_model=ResponseModel,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_completion_tokens=1000,\n",
    "    )\n",
    "\n",
    "    return response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64e237a6-674b-42ef-838d-f8365b890c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "user_prompt = \"What's the weather like in San Francisco?\"\n",
    "tool_calls = run_conversation(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "979e32c6-90b1-424b-b10f-55032c6b58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "Tool: get_weather_info\n",
      "Parameters: {\"location\": \"San Francisco\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for call in tool_calls:\n",
    "    print(f\"Input: {call.input_text}\")\n",
    "    print(f\"Tool: {call.tool_name}\")\n",
    "    print(f\"Parameters: {call.tool_parameters}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d9d52-311f-4110-a7bc-b76e7cad2525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644c955-3e6e-4538-be85-85d6c0d4d4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8e180-5e27-421c-8941-af9d22d71140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7f77c-9444-4bdd-8d0c-b5a50568580a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae5c1e-4a02-4f36-a199-d1758dc6cd46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
